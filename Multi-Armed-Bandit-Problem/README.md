# Multi-armed bandit Problem

## Description

This folder contains three basic algorithm to solve the multi-armed bandit Problem:

* Random selection
* Upper Confidence Bound (UCB)
* Thompson Sampling

## Understanding the the multi-armed bandit problem

## Results



# Reinforcement Learning Basic Algorithms

## Description
This repository provides the implementation of the basic reinforcement learning algorithms which we implemented as programming assignments of the <a href="https://www.coursera.org/learn/practical-rl" target="blank">practical reinforcement learning MOOC</a> on Coursera, including the honors track assignments.

This MOOC lasts 6 weeks and allowed us to implement different algorithms each week:
* Week 1:
   * [Cross Entropy Method](./week1/02_crossentropy_method.ipynb){:target="_blank"}
   * [Deep Cross Entropy Method](./week1/03_deep_crossentropy_method.ipynb){:target="_blank"}
   
* Week 2:
   * [Value Iteration](./week2/04_practice_value_iteration.ipynb){:target="_blank"}

* Week 3:
   * [Vanilla Q-Learning](./week3/05_qlearning.ipynb){:target="_blank"}
   * [Expected SARSA](./week3/06_sarsa.ipynb){:target="_blank"}
   * [Q-Learning with experience replay](./week3/07_experience_replay.ipynb){:target="_blank"}
     
* Week 4:
   * [Approximate Q-Learning](./week4/08_practice_approx_qlearning.ipynb){:target="_blank"}
   * [Deep Q-Learning](./week4/09_dqn_atari.ipynb){:target="_blank"}

* Week 5:
   * [REINFORCE](./week5/10_practice_reinforce.ipynb){:target="_blank"}
   * [A3C](./week5/11_practice_a3c.ipynb){:target="_blank"}

* Week 6:
   * [Bandits and exploration](./week6/12_bandits.ipynb){:target="_blank"}
   * [Monte Carlo Tree Search (MCTS)](./week6/13_practice_mcts.ipynb){:target="_blank"}
   
   ## Running
